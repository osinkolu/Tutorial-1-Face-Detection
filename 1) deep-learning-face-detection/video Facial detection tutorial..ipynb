{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Detection in Videos with Opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've been able to apply facial detection on images, we now move into applying facial detection to videos, video streams as well as webcams. It's really just almost the same concept. Once again, a big thanks to Aleksandr Rybnikov and his team for making this easy for users of opencv3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as earlier, we import the necessary packages.\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three special imports we need here are VideoStream, imutils and time.To successfully install if you do not have, open your enviroment and install via \"pip install imutils\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face detector model is currently loading....\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# we load in our facial detector caffe model. just copy and paste from the image detection or type along.\n",
    "\n",
    "# load the face detector model from filepath\n",
    "print(\"face detector model is currently loading....\")\n",
    "# set address of prototxt file\n",
    "prototxtPath = \"face_detector/deploy.prototxt\"\n",
    "# set the address of the caffe_model\n",
    "weightsPath = \"face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "\n",
    "\"\"\" NOTE THAT YOUR ADDRESS OF PROTOTXTPATH AND WEIGHTSPATH SHOULD BE SIMILAR TO THAT OF OpenCV's I.E ...../face_detector/ the file to load\"\"\"\n",
    "\n",
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next phase, we'll initialize the Video stream and allow the camera to warm up briefly, i set my warm up time to about 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing Video stream,\n"
     ]
    }
   ],
   "source": [
    "print(\"initializing Video stream,\")\n",
    "vs = VideoStream(src = 0).start() #start the video stream\n",
    "time.sleep(2.0) #set sleep time to 2.0 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Just in case you want to load in a video file, you can replace the VideoStream class above with FileVideoStream\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we loop over the frames of the video stream\n",
    "while True:\n",
    "    #we grab the video frame and resize it's width to 400 pixels maximum\n",
    "    frame = vs.read() #read per frame of your video stream\n",
    "    frame = imutils.resize(frame, width=400)# resize the video stream to a reasonable ratio.\n",
    "    \n",
    "    \"\"\" grab the frame you read off and convert to an input blob\"\"\"\n",
    "    (h,w) = frame.shape[:2] #pick height and weight from frame.\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300,300)),1.0,(300,300),(104.0,177.0,123.0))\n",
    "    \n",
    "    \"\"\" pass the blob through the network and obtain detections and predictions\"\"\"\n",
    "    net.setInput(blob) #give blob to the neural network\n",
    "    detections = net.forward()\n",
    "    #loop over the detections:\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        #extract it's confidence of detection\n",
    "        confidence = detections[0,0,i,2]\n",
    "        # filter out the weak detections by ensuring confidence is greater than 0.5\n",
    "        if confidence > 0.5:\n",
    "            #if satisfied, we compute the x, y co-ordinates for the bounding box\n",
    "            box = detections[0,0,i,3:7] * np.array([w,h,w,h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        \n",
    "            #Now draw the bounding box since you have correct dimensions\n",
    "            # Also, let's write the confidence of the model in text to be displayed.\n",
    "            text = str(confidence * 100) #this is the text\n",
    "       \n",
    "            #just in case the face is at the edge, we adjust where to write\n",
    "            y = startY -10 if startY -10 > 10 else startY + 10 \n",
    "            #tell cv to draw your rectangle and write your text as well, \n",
    "            cv2.rectangle(frame, (startX, startY), (endX,endY), (0,225,0),2)\n",
    "            #specify your desired font too as well as other params, press shft + tab to see.\n",
    "            cv2.putText(frame, text, (startX, y),cv2.FONT_ITALIC, 0.5,(0,225,0),2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "     # Closing a video frame\n",
    "    key = cv2.waitKey(1) #wait for the cv key\n",
    "    if key == ord(\"x\"): # If the x button is pressed\n",
    "        break # Break from the loop\n",
    "vs.release() # Let opencv release the video loader\n",
    "cv2.destroyAllWindows() # Destroy all windows to close it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end of tutorial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
